{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb659afe-c7cf-42c0-a484-1aed37fd2900",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'language' from 'google.cloud' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpydata_google_auth\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moauth2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m service_account\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m language\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m \n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m storage \n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'language' from 'google.cloud' (unknown location)"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import requests\n",
    "import os \n",
    "import pydata_google_auth\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud import language\n",
    "import json \n",
    "from google.cloud import storage \n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Main function. \n",
    "\n",
    "def get_today_news():\n",
    "    \n",
    "    # Authenticate to GCP. \n",
    "  \n",
    "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=''\n",
    "\n",
    "    # Make initial request to Reddit API to return a token.\n",
    "\n",
    "    auth = requests.auth.HTTPBasicAuth('CLIENT_ID', 'SECRET_TOKEN')\n",
    "    data = {\n",
    "    'grant_type': 'client_credentials',\n",
    "    'username': 'username',\n",
    "    'password': 'password'\n",
    "    }\n",
    "    headers = {'User-Agent': 'News/0.0.1'}\n",
    "    request = requests.post('https://www.reddit.com/api/v1/access_token', auth=auth, data=data, headers=headers)\n",
    "    token = request.json()['access_token']\n",
    "    headers = {**headers, **{'Authorization': f\"bearer {token}\"}}\n",
    "    \n",
    "    # Make the request to the desired subreddit: r/news. \n",
    "\n",
    "    news_requests = requests.get('https://oauth.reddit.com/r/news/hot', headers=headers, params={'limit': '100'})\n",
    "\n",
    "    # Transformations. \n",
    "\n",
    "    # Loop through the returned JSON body to create our columns.\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    for post in news_requests.json()['data']['children']:\n",
    "        df = df.append({\n",
    "        'title': post['data']['title'],\n",
    "        'upvote_ratio': post['data']['upvote_ratio'],\n",
    "        'score': post['data']['score'],\n",
    "        'ups': post['data']['ups'],\n",
    "        'domain': post['data']['domain'],\n",
    "        'num_comments': post['data']['num_comments']\n",
    "    }, ignore_index=True)\n",
    "    \n",
    "    # Establish a BigQuery client. \n",
    "\n",
    "    client = bigquery.Client()\n",
    "    news_dataset_id = 'reddit_news'\n",
    "    news_table_id = 'r_news'\n",
    "    \n",
    "    news_ref = client.dataset(news_dataset_id)\n",
    "    news_table_id = news_ref.table(news_table_id)\n",
    "    \n",
    "    # Configure the load job.\n",
    "\n",
    "    job_config = bigquery.LoadJobConfig()\n",
    "    job_config.write_disposition='WRITE_TRUNCATE'\n",
    "    job_config.source_format = bigquery.SourceFormat.CSV\n",
    "    job_config.autodetect=True\n",
    "    job_config.ignore_unknown_values=True \n",
    "\n",
    "    # Load the data to the \"r_news\" table. \n",
    "\n",
    "    job = client.load_table_from_dataframe(\n",
    "    df,\n",
    "    news_table_id,\n",
    "    location='US',\n",
    "    job_config=job_config)\n",
    "\n",
    "    job.result()\n",
    "\n",
    "    # Print a message when complete. \n",
    "\n",
    "    print('News table loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2eda7f6-e332-48d5-89a2-178b990f0b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78468606-a6fe-4b93-ba42-afce6f35a6f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcd22a8-8bed-4c46-8faa-cf9f1f7697ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7858fe99-d7dd-424d-b080-6ed5842b5e52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e628878-67d0-4f2c-93fd-b9d77e7e04c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
