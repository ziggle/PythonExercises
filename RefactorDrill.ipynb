{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb659afe-c7cf-42c0-a484-1aed37fd2900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google.cloud\n",
      "  Downloading google_cloud-0.34.0-py2.py3-none-any.whl (1.8 kB)\n",
      "Installing collected packages: google.cloud\n",
      "Successfully installed google.cloud-0.34.0\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.cloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpydata_google_auth\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moauth2\u001b[39;00m \u001b[39mimport\u001b[39;00m service_account\n\u001b[1;32m----> 9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcloud\u001b[39;00m \u001b[39mimport\u001b[39;00m language\n\u001b[0;32m     10\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjson\u001b[39;00m \n\u001b[0;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcloud\u001b[39;00m \u001b[39mimport\u001b[39;00m storage \n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.cloud'"
     ]
    }
   ],
   "source": [
    "#! pip install requests\n",
    "#! pip install pydata_google_auth\n",
    "#! pip install google.cloud\n",
    "import pandas as pd \n",
    "import requests\n",
    "import os \n",
    "import pydata_google_auth\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud import language\n",
    "import json \n",
    "from google.cloud import storage \n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Main function. \n",
    "\n",
    "def get_today_news():\n",
    "    \n",
    "    # Authenticate to GCP. \n",
    "  \n",
    "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=''\n",
    "\n",
    "    # Make initial request to Reddit API to return a token.\n",
    "\n",
    "    auth = requests.auth.HTTPBasicAuth('CLIENT_ID', 'SECRET_TOKEN')\n",
    "    data = {\n",
    "    'grant_type': 'client_credentials',\n",
    "    'username': 'username',\n",
    "    'password': 'password'\n",
    "    }\n",
    "    headers = {'User-Agent': 'News/0.0.1'}\n",
    "    request = requests.post('https://www.reddit.com/api/v1/access_token', auth=auth, data=data, headers=headers)\n",
    "    token = request.json()['access_token']\n",
    "    headers = {**headers, **{'Authorization': f\"bearer {token}\"}}\n",
    "    \n",
    "    # Make the request to the desired subreddit: r/news. \n",
    "\n",
    "    news_requests = requests.get('https://oauth.reddit.com/r/news/hot', headers=headers, params={'limit': '100'})\n",
    "\n",
    "    # Transformations. \n",
    "\n",
    "    # Loop through the returned JSON body to create our columns.\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    for post in news_requests.json()['data']['children']:\n",
    "        df = df.append({\n",
    "        'title': post['data']['title'],\n",
    "        'upvote_ratio': post['data']['upvote_ratio'],\n",
    "        'score': post['data']['score'],\n",
    "        'ups': post['data']['ups'],\n",
    "        'domain': post['data']['domain'],\n",
    "        'num_comments': post['data']['num_comments']\n",
    "    }, ignore_index=True)\n",
    "    \n",
    "    # Establish a BigQuery client. \n",
    "\n",
    "    client = bigquery.Client()\n",
    "    news_dataset_id = 'reddit_news'\n",
    "    news_table_id = 'r_news'\n",
    "    \n",
    "    news_ref = client.dataset(news_dataset_id)\n",
    "    news_table_id = news_ref.table(news_table_id)\n",
    "    \n",
    "    # Configure the load job.\n",
    "\n",
    "    job_config = bigquery.LoadJobConfig()\n",
    "    job_config.write_disposition='WRITE_TRUNCATE'\n",
    "    job_config.source_format = bigquery.SourceFormat.CSV\n",
    "    job_config.autodetect=True\n",
    "    job_config.ignore_unknown_values=True \n",
    "\n",
    "    # Load the data to the \"r_news\" table. \n",
    "\n",
    "    job = client.load_table_from_dataframe(\n",
    "    df,\n",
    "    news_table_id,\n",
    "    location='US',\n",
    "    job_config=job_config)\n",
    "\n",
    "    job.result()\n",
    "\n",
    "    # Print a message when complete. \n",
    "\n",
    "    print('News table loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7ef796",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
