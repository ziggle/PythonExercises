{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@HalderNilimesh/mastering-model-accuracy-estimation-in-python-a-comprehensive-guide-b50b96906ff3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "# Complete end-to-end code snippet\n",
    "\n",
    "# Importing necessary libraries\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Loading dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Splitting data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Training the model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluating accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Visualization techniques for model accuracy in Python.\n",
    "\n",
    "There are several approaches for visualizing machine learning model accuracy in Python. One of the most commonly used libraries for plotting results of ML algorithms is Matplotlib 1. Another library that provides visualizations for many machine learning metrics related to regression, classification, and clustering is Scikit-Plot "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. How to handle imbalanced data for accurate model evaluation?\n",
    "\n",
    "There are several ways to handle imbalanced data in machine learning models. One of the most effective ways is to downsample and upweight the majority class. Downsampling (in this context) means training on a disproportionately low subset of the majority class examples. Upweighting means adding an example weight to the downsampled class equal to the factor by which you downsampled 1.\n",
    "\n",
    "Other techniques include collecting a bigger sample, oversampling (e.g., random, SMOTE), undersampling (e.g., random, K-Means, Tomek links), combining over and undersampling, weighing classes differently and changing algorithms 23.\n",
    "\n",
    "I hope this helps! Let me know if you have any other questions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
